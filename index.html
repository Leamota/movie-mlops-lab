 <!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <title>Catching Data Drift in Movie Recommendations with Evidently AI</title>
      <style>
        :root {
          --bg: #0f1220;
          --card: #171a2b;
          --text: #e8eaf6;
          --muted: #b8bed8;
          --accent: #73a7ff;
          --code: #0b0e19;
          --border: #232846;
        }
        html, body {
          margin: 0; padding: 0; background: var(--bg); color: var(--text);
          font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
          line-height: 1.6;
        }
        .container { max-width: 880px; margin: 0 auto; padding: 40px 20px; }
        header { margin-bottom: 28px; }
        h1 { font-size: 2rem; margin: 0; }
        .subtitle { color: var(--muted); margin-top: 8px; }
        .card {
          background: var(--card); border: 1px solid var(--border); border-radius: 12px;
          padding: 20px; margin: 18px 0;
        }
        h2 { font-size: 1.25rem; margin: 24px 0 8px; }
        p { margin: 12px 0; }
        ul, ol { margin: 10px 0 10px 24px; }
        a { color: var(--accent); text-decoration: none; }
        a:hover { text-decoration: underline; }
        code, pre {
          font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
        }
        pre {
          background: var(--code); border: 1px solid var(--border);
          padding: 14px; border-radius: 10px; overflow-x: auto; color: #cfe3ff;
        }
        .metric {
          display: inline-block; background: #102544; border: 1px solid #234a86;
          color: #cfe3ff; padding: 8px 12px; border-radius: 999px; margin-right: 8px; font-weight: 600;
        }
        .img {
          display: block; width: 100%; max-width: 100%; border-radius: 12px;
          border: 1px solid var(--border); margin: 14px 0;
        }
        footer { color: var(--muted); margin-top: 28px; font-size: 0.95rem; text-align: center; }
        .hr { height: 1px; border: none; background: var(--border); margin: 24px 0; }
      </style>
    </head>
    <body>
      <main class="container">
        <header>
          <h1>ðŸŽ¬ Catching Data Drift in Movie Recommendations with Evidently AI</h1>
          <p class="subtitle">How a lightweight monitoring workflow reveals shifting user tastes and keeps recommendations relevant.</p>
        </header>

        <section class="card">
          <h2>Introduction</h2>
          <p>
            The recommendation system in movie streaming services relies on the user's behavior to suggest films, but user tastes are subject to rapid change. It is possible for thrillers to 
            dominate one month, while animated shows may gain popularity the next. The recommendations generated by machine learning modele are outdated
            or relevant if they are not adpted. Maintaining relevance and accuracy of recommendations over time requires continuous monitoring of user behavior
            and detecting data drift.
          </p>
          <p>
            <strong>Data drift</strong>, the statistical changes in the properties of input data over time, which can make recommendation appear outdated or irrelevant.
              Occurs when the incoming data no longer aligns with the data the models was originally trained on. 
          <p>    
              In this post, I demonstarted how this challenge can be
              addressed in an experiment using <strong>Evidently AI</strong>, an openâ€‘source monitoring tool, to detect drift in a simulated movieâ€‘streaming scenario.
          </p>
        </section>

        <section class="card">
          <h2>Baseline model results</h2>
          <p>
            In order to predict user behavior, a simple watch-probability model was developed. The model predicts whether a user is likely to watch a movie
            based on regions, device, age group and genre affinities.
            
          </p>
          <p>
            Baseline performance:
          </p>
          <p>
            <span class="metric">ROCâ€‘AUC: 0.705</span>
            <span class="metric">PRâ€‘AUC: 0.562</span>
          </p>
          <p>
            in spite of these imperfections, the scores show that the model is learning meaniful patterns - enough to show that dfirt monitoring is performed.
          </p>
        </section>

        <section class="card">
          <h2>Simulating drift</h2>
          <p>
            I simulated realworld change by introducing an increase in animated shows interest. Comparing the "current" datset to the "reference", users
            are more inclined to like animated shows than non-animated.
          
            In production, trends in content or demographic shift can quickly dimish the relevance of yesterdayâ€™s model.
          
          </p>
          <img class="img" src="images/genre_distribution.png" alt="Genre distribution before vs after drift" />
        </section>

        <section class="card">
          <h2>Monitoring with Evidently</h2>
          <p>
            I used Evidentlyâ€™s <em>DataDriftPreset</em> to compare reference vs. current data and generate an HTML dashboard.
          </p>
          <pre><code>from evidently import Report
    from evidently.metric_preset import DataDriftPreset

    report = Report(metrics=[DataDriftPreset()])
    report.run(reference_data=ref_logs, current_data=cur_logs)
    report.save_html("data_drift_report.html")</code></pre>
          <p>
            Opening the dashboard revealed clear changes:
          </p>
          <ul>
            <li><strong>Feature drift:</strong> <code>genre_anime</code> and <code>aff_anime</code> distributions shifted significantly.</li>
            <li><strong>Prediction drift:</strong> The modelâ€™s score distribution changed, indicating calibration issues.</li>
            <li><strong>Target drift:</strong> Watch outcomes differed between reference and current periods.</li>
          </ul>
          <img class="img" src="images/evidently_report.png" alt="Evidently drift dashboard screenshot" />
        </section>

        <section class="card">
          <h2>Insights and takeaways</h2>
          <ul>
            <li><strong>Models degrade silently:</strong> Without monitoring, recommendations can become irrelevant without obvious failures.</li>
            <li><strong>Evidently surfaces instability:</strong> The dashboard highlights which features are drifting, guiding retraining decisions.</li>
            <li><strong>Operational workflow:</strong> In production, set thresholds (e.g., drift share &gt; 0.3) to trigger alerts or automated retraining.</li>
          </ul>
          <pre><code># Programmatic summary example
    summary = report.as_dict()
    drifted = summary["metrics"][0]["result"]["data_drift"]["dataset_drift"]
    drift_share = summary["metrics"][0]["result"]["data_drift"]["drift_share"]
    print(f"Dataset drift: {drifted}, drift share: {drift_share:.2f}")</code></pre>
        </section>

        <section class="card">
          <h2>Conclusion</h2>
          <p>
            Maintaining ML model is an important part of machine learning production. A movie streaming platform that catches drift early will have happier user and better engagement.
           
            This experiment demonstrates how <strong>Evidently AI</strong> can serve as a lightweight, accessible guardrail for recommendation systems.
          
          
        </section>

        <hr class="hr" />
        <footer>
           Lawrence A. Egharevba | 
            <strong>Course:</strong> COT 6930: AI and Machine Learning Prod | 
            <strong>Institution:</strong> Florida Atlantic University | 
            <em>Fall 2025</em></p>
        </footer>
      </main>
    </body>
    </html>
